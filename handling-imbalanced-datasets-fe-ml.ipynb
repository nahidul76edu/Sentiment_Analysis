{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load Processed Data","metadata":{}},{"cell_type":"code","source":"imdb_dataset_processed = pd.read_csv('/kaggle/input/sentiments-processed/imdb_dataset_processed.csv')\nprint('imdb_dataset_processed done')\nUSAirline_dataset_processed =  pd.read_csv('/kaggle/input/sentiments-processed/USAirline_dataset_processed.csv')\nprint('USAirline_dataset_processed done')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now Check Nan value\nprint(\"imdb_dataset_processed:\", imdb_dataset_processed.isnull().sum())\nprint(\"USAirline_dataset_processed:\",USAirline_dataset_processed.isnull().sum())\n\nprint(\"Before check null\", len(imdb_dataset_processed))\nprint(\"Before check null\", len(USAirline_dataset_processed))\nprint(\"\")\n\nimdb_dataset_processed = imdb_dataset_processed.dropna()\nUSAirline_dataset_processed = USAirline_dataset_processed.dropna()\n\nprint(\"After drop null\", len(imdb_dataset_processed))\nprint(\"After drop null\", len(USAirline_dataset_processed))\nprint(\"\")\n#Now Check Nan value\nprint(\"AFTER imdb_dataset_processed:\", imdb_dataset_processed.isnull().sum())\nprint(\"AFTER USAirline_dataset_processed:\",USAirline_dataset_processed.isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data reLabel:  LabelEncoder","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# imdb_dataset, USAirline_dataset, and Sentiment140_dataset\n\n# Initialize the LabelEncoder\nle = LabelEncoder()\n# Label Encoding for each dataset\n#imdb_dataset['sentiment'], ['sentiment'] CONTAINS LABELS\nencoded_label_imdb = le.fit_transform(imdb_dataset_processed['sentiment']) \nencoded_label_USAirline = le.fit_transform(USAirline_dataset_processed['sentiment'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# feature extraction","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\n# Instantiate each vectorizer individually\ntfidf_vectorizer = TfidfVectorizer()\ncount_vectorizer = CountVectorizer()\n\n# Vectorize the 'review' column for each dataset with TF-IDF\nimdb_dataset_tfidf = tfidf_vectorizer.fit_transform(imdb_dataset_processed['review_P'])\nimdb_dataset_CountVectorizer = count_vectorizer.fit_transform(imdb_dataset_processed['review_P'])\nprint('\\n------------->imdb_dataset: I AM DONE<-------------------')\n\nUSAirline_dataset_tfidf = tfidf_vectorizer.fit_transform(USAirline_dataset_processed['review_P'])\nUSAirline_dataset_CountVectorizer = count_vectorizer.fit_transform(USAirline_dataset_processed['review_P'])\nprint('\\n------------->USAirline_dataset: I AM DONE<-------------------')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Imbalanced Datasets","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# Initialize SMOTE\nsmote = SMOTE() #SMOTE(random_state=42)\n#imdb_dataset is balanced\n###########################################################################################################################################\nX_train_usairline_tfidf, y_train_usairline_tfidf = smote.fit_resample(USAirline_dataset_tfidf, encoded_label_USAirline)\nX_train_usairline_CountVectorizer, y_train_usairline_CountVectorizer = smote.fit_resample(USAirline_dataset_CountVectorizer, encoded_label_USAirline)\nprint('\\n------------->USAirline_dataset_fidf: I AM DONE<-------------------')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the class distribution after smote","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\n# Checking class distribution in y_train_usairline_tfidf\nclass_distribution_tfidf = Counter(y_train_usairline_tfidf)\nprint(\"Class distribution in USAirline_dataset_tfidf after SMOTE:\")\nfor k, v in class_distribution_tfidf.items():\n    print(f\"Class {k}: {v} instances\")\n\n# Checking class distribution in y_train_usairline_CountVectorizer\nclass_distribution_cv = Counter(y_train_usairline_CountVectorizer)\nprint(\"\\nClass distribution in USAirline_dataset_CountVectorizer after SMOTE:\")\nfor k, v in class_distribution_cv.items():\n    print(f\"Class {k}: {v} instances\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Datasets and their labels (assuming these are defined somewhere in your code)\ndatasets = {\n    \"imdb_tfidf\": (imdb_dataset_tfidf, encoded_label_imdb),\n    \"imdb_count\": (imdb_dataset_CountVectorizer, encoded_label_imdb),\n    \"usairline_tfidf\": (X_train_usairline_tfidf, y_train_usairline_tfidf),\n    \"usairline_count\": (X_train_usairline_CountVectorizer, y_train_usairline_CountVectorizer),\n}\n\n# Splitting function\ndef split_dataset(X, y, test_size=0.2, random_state=0):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    return X_train, X_test, y_train, y_test\n\n# Splitting datasets\nsplit_datasets = {}\nfor name, (X, y) in datasets.items():\n    X_train, X_test, y_train, y_test = split_dataset(X, y)\n    split_datasets[name] = {\n        \"X_train\": X_train,\n        \"X_test\": X_test,\n        \"y_train\": y_train,\n        \"y_test\": y_test\n    }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dynamically selection**","metadata":{}},{"cell_type":"code","source":"# Dynamically selecting a dataset\nselected_dataset = \"imdb_tfidf\" # you can choose any dataset from datasets","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Apply FE + ML Models on each datasets ","metadata":{}},{"cell_type":"code","source":"X_train = split_datasets[selected_dataset][\"X_train\"]\nX_test = split_datasets[selected_dataset][\"X_test\"]\ny_train = split_datasets[selected_dataset][\"y_train\"]\ny_test = split_datasets[selected_dataset][\"y_test\"]\n\n# Extracting dataset name and transformation for dynamic updates\ndataset_name, transformation = selected_dataset.split('_')\nformatted_dataset_name = dataset_name.upper()\nformatted_transformation = transformation.upper()\n\n# Models dictionary\nmodels = {\n    'Logistic Regression': LogisticRegression(random_state=0),\n    'SVM': CalibratedClassifierCV(LinearSVC(random_state=0), cv=10),\n    'Passive_Aggressive': PassiveAggressiveClassifier(random_state=0),\n    'RandomForest': RandomForestClassifier(random_state=0),\n    'AdaBoost': AdaBoostClassifier(random_state=0),\n    'MultinomialNB': MultinomialNB(),\n    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=0)\n}\n\n# Results dictionary\nresults = {}\n\n# Training, prediction, and evaluation function\ndef train_predict_evaluate(model, X_train, X_test, y_train, y_test):\n    try:\n        model.fit(X_train, y_train)\n        predictions = model.predict(X_test)\n        accuracy = accuracy_score(y_test, predictions)\n        class_report = classification_report(y_test, predictions, digits=4)\n        return accuracy, class_report\n    except Exception as e:\n        return str(e), str(e)\n\n# Evaluating models\nprint(f\"Evaluating models on {formatted_dataset_name} dataset with {formatted_transformation} transformation\")\nfor model_name, model in models.items():\n    accuracy, class_report = train_predict_evaluate(model, X_train, X_test, y_train, y_test)\n    results[model_name] = (accuracy, class_report)\n    print(f\"\\nModel: {model_name} ({formatted_transformation})\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(\"Classification Report:\")\n    print(class_report)\n        \n# Dynamically setting the output filename based on the selected dataset\noutput_filename = f\"/kaggle/working/model_for_{dataset_name}_{transformation}.txt\"\n\nwith open(output_filename, \"w\") as file:\n    file.write(f\"Evaluating models on {formatted_dataset_name} dataset with {formatted_transformation} transformation\\n\")\n    for model_name, (accuracy, class_report) in results.items():\n        file.write(f\"\\nModel: {model_name} ({formatted_transformation})\\n\")\n        file.write(f\"Accuracy: {accuracy:.4f}\\n\")\n        file.write(\"Classification Report:\\n\")\n        file.write(f\"{class_report}\\n\")","metadata":{},"execution_count":null,"outputs":[]}]}